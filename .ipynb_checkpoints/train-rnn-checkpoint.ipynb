{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "import itertools\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.optim import SGD\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from lstm import LSTM\n",
    "from music_dataloader import create_split_loaders\n",
    "from torch_utils import setup_device\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is supported\n"
     ]
    }
   ],
   "source": [
    "computing_device = setup_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader, dictionary = create_split_loaders(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, loader, criterion):\n",
    "    model.eval()\n",
    "    return torch.mean(torch.tensor([criterion(torch.squeeze(model(torch.unsqueeze(x.to(computing_device), 0))), y.to(computing_device)) \\\n",
    "                       for x, y in loader]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_rnn(model, criterion, optimizer, train_loader, val_loader, n_epochs, model_name, seq_length=100, \n",
    "            chkpt_every=100, update_hist=50, val_every=1000):\n",
    "    train_losses = dict()\n",
    "    val_losses = dict()\n",
    "    total_seen = 0\n",
    "    start_time = dt.now()\n",
    "    \n",
    "    # Make the directory to save the model and the losses\n",
    "    if not os.path.exists('models'):\n",
    "        os.mkdir('models')\n",
    "    if not os.path.exists('train-stats'):\n",
    "        os.mkdir('train-stats')\n",
    "    model_save_path = os.path.join('models', model_name + '.pt')\n",
    "    train_save_path = os.path.join('train-stats', model_name + '_train.pkl')\n",
    "    val_save_path = os.path.join('train-stats', model_name + '_val.pkl')\n",
    "    \n",
    "    for epoch in np.arange(n_epochs):\n",
    "        train_losses[epoch] = []\n",
    "        val_losses[epoch] = []\n",
    "        model.train()\n",
    "        model.reset_state()\n",
    "        print('======= ' + str(epoch) + ' ========')\n",
    "#         for p in model.parameters():\n",
    "#             print(p)\n",
    "        optimizer.zero_grad()\n",
    "        for i, (x, y) in enumerate(train_loader):\n",
    "            x = x.to(computing_device)\n",
    "            y = y.to(computing_device)\n",
    "            \n",
    "            loss = criterion(torch.squeeze(model(torch.unsqueeze(x, 0))), y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # Question about efficiency with the detachment every iteration\n",
    "            train_losses[epoch].append(loss.detach().cpu().numpy())\n",
    "            #print(type(loss.data.tolist()))\n",
    "            #print(train_losses[0][0])\n",
    "            total_seen += 1\n",
    "            \n",
    "            # Report training stats\n",
    "            avg_loss = np.mean(train_losses[epoch])\n",
    "            time_delta = dt.now() - start_time\n",
    "            update_str = '[TIME ELAPSED]: {0} [EPOCH {1}]: Avg. loss current epoch: {2:0.5f}'\n",
    "            print(update_str.format(str(time_delta),epoch + 1, avg_loss), end='\\r')\n",
    "            \n",
    "            # Save the model and the training and validation losses\n",
    "            if not total_seen % chkpt_every:\n",
    "                torch.save(model.state_dict(), model_save_path)\n",
    "                with open(train_save_path, 'wb') as f:\n",
    "                    pickle.dump(train_losses, f)\n",
    "                with open(val_save_path, 'wb') as f:\n",
    "                    pickle.dump(val_losses, f)\n",
    "            if not total_seen % val_every:\n",
    "                # Validate the model\n",
    "                val_losses[epoch].append(evaluate_model(model, val_loader, criterion))\n",
    "                model.train()\n",
    "\n",
    "        print('')\n",
    "        \n",
    "        val_losses[epoch] = evaluate_model(model, val_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = LSTM(len(dictionary), 150, len(dictionary), 1)\n",
    "criterion = nn.CrossEntropyLoss().to(computing_device)\n",
    "lstm.to(computing_device)\n",
    "optimizer = SGD(lstm.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= 0 ========\n",
      "[TIME ELAPSED]: 0:00:53.770281 [EPOCH 1]: Avg. loss for last 100 minibatches: 3.49348\n",
      "======= 1 ========\n",
      "[TIME ELAPSED]: 0:01:30.762806 [EPOCH 2]: Avg. loss for last 100 minibatches: 3.28812\r"
     ]
    }
   ],
   "source": [
    "fit_rnn(lstm, criterion, optimizer, train_loader, val_loader, 100, 'lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tune(model):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
